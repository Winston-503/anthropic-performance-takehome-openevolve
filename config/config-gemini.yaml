# OpenEvolve Configuration for Anthropic Performance Takehome
# Using Gemini 2.0 Flash for initial testing with small iterations

max_iterations: 15
checkpoint_interval: 5
max_code_length: 1000000
random_seed: null

llm:
  models:
    - name: "gemini-3-pro-preview"
      weight: 1.0
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
      api_key: "${GEMINI_API_KEY}"

  temperature: 0.7
  max_tokens: 64000
  timeout: 600

database:
  population_size: 50
  archive_size: 20
  num_islands: 2
  feature_dimensions: ["complexity", "diversity"]
  feature_bins: 5
  migration_interval: 10

evaluator:
  timeout: 120
  parallel_evaluations: 1
  cascade_evaluation: true
  cascade_thresholds: [0.5, 0.75]

prompt:
  system_message: |
    You are an expert performance engineer optimizing code for a custom VLIW SIMD architecture.

    ## Full Machine Definition (problem.py)

    Study this carefully to understand the exact instruction semantics:

    ```python
    {problem_py}
    ```

  suggest_simplification_after_chars: null
  concise_implementation_max_lines: null
  comprehensive_implementation_min_lines: null
  diff_summary_max_lines: 10000
  num_top_programs: 3
  num_diverse_programs: 2
