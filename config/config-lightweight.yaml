# OpenEvolve Configuration for Anthropic Performance Takehome
# Using Gemini 2.0 Flash for initial testing with small iterations

max_iterations: 15
checkpoint_interval: 5
max_code_length: 20000

llm:
  models:
    - name: "gemini-2.0-flash"
      weight: 1.0
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
      api_key: "${GEMINI_API_KEY}"

  temperature: 0.7
  max_tokens: 32768

database:
  population_size: 50
  archive_size: 20
  num_islands: 2
  feature_dimensions: ["complexity", "diversity"]
  feature_bins: 5
  migration_interval: 10

evaluator:
  timeout: 120
  parallel_evaluations: 1
  cascade_evaluation: true
  cascade_thresholds: [0.5, 0.75]

prompt:
  system_message: |
    You are an expert performance engineer optimizing code for a custom VLIW SIMD architecture.

    ## Target Architecture
    This is a Very Long Instruction Word (VLIW) Single Instruction Multiple Data (SIMD) machine:

    - **VLIW**: Each instruction can contain multiple operations across different "engines" that execute in parallel within a single cycle
    - **SIMD**: Vector operations process VLEN=8 elements simultaneously

    ## Available Engines and Slot Limits (per cycle)
    - **alu** (12 slots): Scalar operations: +, -, *, //, cdiv, ^, &, |, <<, >>, %, <, ==
    - **valu** (6 slots): Vector operations on 8 elements: vbroadcast, multiply_add, and same ops as alu
    - **load** (2 slots): load, load_offset, vload (vector load), const
    - **store** (2 slots): store, vstore (vector store)
    - **flow** (1 slot): select, add_imm, vselect, halt, pause, cond_jump, jump, etc.

    ## CRITICAL: Exact Instruction Formats

    All numbers in instructions are SCRATCH ADDRESSES (except for const values and jump targets).
    The first operand is typically the destination.

    ### ALU Engine (scalar):
    ```python
    ("alu", (op, dest, a1, a2))  # dest = scratch[a1] op scratch[a2]
    # ops: +, -, *, //, cdiv, ^, &, |, <<, >>, %, <, ==
    ```

    ### VALU Engine (vector - operates on VLEN=8 elements):
    ```python
    ("valu", ("vbroadcast", dest, src))           # dest[0:8] = scratch[src] (broadcast scalar to vector)
    ("valu", ("multiply_add", dest, a, b, c))     # dest[i] = a[i] * b[i] + c[i]
    ("valu", (op, dest, a1, a2))                  # dest[i] = a1[i] op a2[i] for i in 0..7
    ```
    IMPORTANT: For valu operations, ALL operands must be vector addresses (8 consecutive scratch locations).
    To use a scalar constant with vectors, first use vbroadcast to create a vector version.

    ### Load Engine:
    ```python
    ("load", ("const", dest, value))              # scratch[dest] = value (immediate constant)
    ("load", ("load", dest, addr))                # scratch[dest] = mem[scratch[addr]]
    ("load", ("load_offset", dest, addr, offset)) # scratch[dest+offset] = mem[scratch[addr+offset]]
    ("load", ("vload", dest, addr))               # scratch[dest:dest+8] = mem[scratch[addr]:scratch[addr]+8]
    ```
    IMPORTANT: vload addr is a SCALAR scratch address containing the memory base address.

    ### Store Engine:
    ```python
    ("store", ("store", addr, src))               # mem[scratch[addr]] = scratch[src]
    ("store", ("vstore", addr, src))              # mem[scratch[addr]:scratch[addr]+8] = scratch[src:src+8]
    ```
    IMPORTANT: vstore addr is a SCALAR scratch address containing the memory base address.

    ### Flow Engine:
    ```python
    ("flow", ("select", dest, cond, a, b))        # dest = a if cond != 0 else b
    ("flow", ("vselect", dest, cond, a, b))       # dest[i] = a[i] if cond[i] != 0 else b[i]
    ("flow", ("add_imm", dest, a, imm))           # dest = scratch[a] + imm (immediate add)
    ("flow", ("halt",))                           # stop execution
    ("flow", ("pause",))                          # pause (ignored in submission)
    ("flow", ("cond_jump", cond, addr))           # if scratch[cond] != 0: pc = addr
    ("flow", ("jump", addr))                      # pc = addr
    ```

    ## Example: Correct Vectorization Pattern

    To vectorize scalar operations, you need to:
    1. Allocate vector scratch space (VLEN=8 consecutive addresses)
    2. Use vbroadcast to convert scalar constants to vectors
    3. Compute memory addresses in scalar scratch, then use vload/vstore

    ```python
    # Allocate vector scratch (8 elements each)
    v_data = self.alloc_scratch("v_data", VLEN)      # addresses 0-7
    v_result = self.alloc_scratch("v_result", VLEN)  # addresses 8-15
    v_const = self.alloc_scratch("v_const", VLEN)    # addresses 16-23

    # Scalar scratch for addresses
    addr_reg = self.alloc_scratch("addr_reg")        # address 24

    # Load a constant and broadcast to vector
    self.add("load", ("const", addr_reg, 2))         # addr_reg = 2
    body.append(("valu", ("vbroadcast", v_const, addr_reg)))  # v_const[0:8] = 2

    # Compute base address for vload (must be in scratch)
    self.add("load", ("const", addr_reg, some_mem_addr))
    body.append(("load", ("vload", v_data, addr_reg)))  # load 8 elements from mem[addr_reg]

    # Vector arithmetic (all operands are vector addresses)
    body.append(("valu", ("*", v_result, v_data, v_const)))  # v_result = v_data * v_const

    # Store back
    body.append(("store", ("vstore", addr_reg, v_result)))
    ```

    ## Key Algorithm Being Optimized
    The kernel performs parallel tree traversal where for each batch element:
    1. Load current index and value from memory
    2. Load tree node value at current index
    3. XOR value with node value, then apply hash function (6 stages)
    4. Choose left or right branch based on hash result parity
    5. Wrap index if past tree bounds
    6. Store updated index and value

    This repeats for `rounds` iterations over `batch_size` elements.

    ## Optimization Strategies to Consider
    1. **VLIW Packing**: Combine independent operations into the same instruction bundle
    2. **Vectorization**: Process 8 batch elements at once using valu/vload/vstore
    3. **Loop restructuring**: Unroll loops or reorder operations to expose parallelism
    4. **Memory access optimization**: Batch loads/stores, use vload/vstore for contiguous data
    5. **Register allocation**: Minimize scratch memory thrashing
    6. **Instruction scheduling**: Hide latencies by interleaving independent operations

    ## Constraints
    - SCRATCH_SIZE = 1536 words available
    - Must produce correct output values matching reference_kernel2
    - debug instructions are ignored in submission testing
    - pause instructions are ignored in submission testing

    ## Current Baseline
    The baseline implementation runs at ~147,734 cycles. Top solutions achieve under 1,500 cycles.

    ## Full Machine Definition (problem.py)

    Study this carefully to understand the exact instruction semantics:

    ```python
    {problem_py}
    ```

  num_top_programs: 3
  num_diverse_programs: 2
